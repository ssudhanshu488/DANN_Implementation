{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPXtiaJHFogZQjSbOajPu/z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ssudhanshu488/DANN_Implementation/blob/main/DANN_Implementation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "2oDEUTW_H_P3"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import os\n",
        "from PIL import Image\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Gradient Reversal Layer\n",
        "class GradientReversal(torch.autograd.Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, x, lambda_):\n",
        "        ctx.lambda_ = lambda_\n",
        "        return x.view_as(x)\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        return -ctx.lambda_ * grad_output, None\n",
        "\n",
        "class GradientReversalLayer(nn.Module):\n",
        "    def __init__(self, lambda_=1.0):\n",
        "        super(GradientReversalLayer, self).__init__()\n",
        "        self.lambda_ = lambda_\n",
        "\n",
        "    def forward(self, x):\n",
        "        return GradientReversal.apply(x, self.lambda_)"
      ],
      "metadata": {
        "id": "Ln2TiOhSIDp9"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DANN Model\n",
        "class DANN(nn.Module):\n",
        "    def __init__(self, num_classes=65):\n",
        "        super(DANN, self).__init__()\n",
        "        # Feature extractor (ResNet-50 without the final layer)\n",
        "        self.feature_extractor = torchvision.models.resnet50(weights='IMAGENET1K_V2')\n",
        "        self.feature_dim = self.feature_extractor.fc.in_features\n",
        "        self.feature_extractor.fc = nn.Identity()  # Remove the final FC layer\n",
        "\n",
        "        # Task classifier\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(self.feature_dim, 1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(1024, num_classes)\n",
        "        )\n",
        "\n",
        "        # Domain discriminator\n",
        "        self.domain_discriminator = nn.Sequential(\n",
        "            GradientReversalLayer(),\n",
        "            nn.Linear(self.feature_dim, 1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(1024, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = self.feature_extractor(x)\n",
        "        class_output = self.classifier(features)\n",
        "        domain_output = self.domain_discriminator(features)\n",
        "        return class_output, domain_output"
      ],
      "metadata": {
        "id": "YsD-HCkiIOCI"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom Dataset for Office-Home\n",
        "class OfficeHomeDataset(Dataset):\n",
        "    def __init__(self, root_dir, domain, transform=None):\n",
        "        self.root_dir = os.path.join(root_dir, domain)\n",
        "        self.transform = transform\n",
        "        self.classes = sorted(os.listdir(self.root_dir))\n",
        "        self.class_to_idx = {cls_name: i for i, cls_name in enumerate(self.classes)}\n",
        "        self.images = []\n",
        "        self.labels = []\n",
        "\n",
        "        for cls_name in self.classes:\n",
        "            cls_dir = os.path.join(self.root_dir, cls_name)\n",
        "            for img_name in os.listdir(cls_dir):\n",
        "                self.images.append(os.path.join(cls_dir, img_name))\n",
        "                self.labels.append(self.class_to_idx[cls_name])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.images[idx]\n",
        "        label = self.labels[idx]\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label"
      ],
      "metadata": {
        "id": "srwN8fUKIndM"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"karntiwari/home-office-dataset\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nImRjnqtJHT8",
        "outputId": "065b86c5-1491-44b0-bba7-add5015c9b3b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/karntiwari/home-office-dataset?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 982M/982M [00:48<00:00, 21.4MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/karntiwari/home-office-dataset/versions/1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls \"/root/.cache/kagglehub/datasets/karntiwari/home-office-dataset/versions/1/OfficeHomeDataset_10072016\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F7Dmm2pkJq7K",
        "outputId": "fd0f8b1a-c22f-4a48-e26f-9a39263c5c08"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " \u001b[0m\u001b[01;34mArt\u001b[0m/   \u001b[01;34mClipart\u001b[0m/   ImageInfo.csv   imagelist.txt  \u001b[01;34m'Real World'\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data loading\n",
        "def get_dataloaders(source_domain, target_domain, data_dir, batch_size=32):\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "    source_dataset = OfficeHomeDataset(data_dir, source_domain, transform=transform)\n",
        "    target_dataset = OfficeHomeDataset(data_dir, target_domain, transform=transform)\n",
        "\n",
        "    source_loader = DataLoader(source_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
        "    target_loader = DataLoader(target_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
        "\n",
        "    return source_loader, target_loader"
      ],
      "metadata": {
        "id": "QbDDVtU0JKKw"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training function\n",
        "def train_dann(model, source_loader, target_loader, optimizer, num_epochs, device):\n",
        "    class_criterion = nn.CrossEntropyLoss()\n",
        "    domain_criterion = nn.BCELoss()\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        len_dataloader = min(len(source_loader), len(target_loader))\n",
        "        data_zip = zip(source_loader, target_loader)\n",
        "\n",
        "        total_class_loss = 0\n",
        "        total_domain_loss = 0\n",
        "        total_correct = 0\n",
        "        total_samples = 0\n",
        "\n",
        "        # Dynamic lambda for gradient reversal\n",
        "        p = float(epoch) / num_epochs\n",
        "        lambda_ = 2. / (1. + np.exp(-10 * p)) - 1\n",
        "\n",
        "        for i, ((source_data, source_labels), (target_data, _)) in enumerate(data_zip):\n",
        "            source_data, source_labels = source_data.to(device), source_labels.to(device)\n",
        "            target_data = target_data.to(device)\n",
        "\n",
        "            # Set domain labels (0 for source, 1 for target)\n",
        "            source_domain_labels = torch.zeros(source_data.size(0), 1).to(device)\n",
        "            target_domain_labels = torch.ones(target_data.size(0), 1).to(device)\n",
        "\n",
        "            # Update gradient reversal lambda\n",
        "            model.domain_discriminator[0].lambda_ = lambda_\n",
        "\n",
        "            # Forward pass\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Source data\n",
        "            class_output, domain_output = model(source_data)\n",
        "            class_loss = class_criterion(class_output, source_labels)\n",
        "            domain_loss_source = domain_criterion(domain_output, source_domain_labels)\n",
        "\n",
        "            # Target data\n",
        "            _, domain_output = model(target_data)\n",
        "            domain_loss_target = domain_criterion(domain_output, target_domain_labels)\n",
        "\n",
        "            # Total loss\n",
        "            total_loss = class_loss + domain_loss_source + domain_loss_target\n",
        "\n",
        "            # Backward and optimize\n",
        "            total_loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Statistics\n",
        "            total_class_loss += class_loss.item()\n",
        "            total_domain_loss += (domain_loss_source.item() + domain_loss_target.item())\n",
        "\n",
        "            _, predicted = torch.max(class_output, 1)\n",
        "            total_correct += (predicted == source_labels).sum().item()\n",
        "            total_samples += source_labels.size(0)\n",
        "\n",
        "        # Print epoch statistics\n",
        "        avg_class_loss = total_class_loss / len_dataloader\n",
        "        avg_domain_loss = total_domain_loss / (2 * len_dataloader)\n",
        "        accuracy = 100. * total_correct / total_samples\n",
        "\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}]')\n",
        "        print(f'Class Loss: {avg_class_loss:.4f}, Domain Loss: {avg_domain_loss:.4f}, Source Accuracy: {accuracy:.2f}%')"
      ],
      "metadata": {
        "id": "l_13BDK9JPuy"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation function\n",
        "def evaluate(model, loader, device):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for data, labels in loader:\n",
        "            data, labels = data.to(device), labels.to(device)\n",
        "            class_output, _ = model(data)\n",
        "            _, predicted = torch.max(class_output, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    accuracy = 100. * correct / total\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "7ukp-UszJX2l"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Main execution\n",
        "def main():\n",
        "    # Configuration\n",
        "    data_dir = '/root/.cache/kagglehub/datasets/karntiwari/home-office-dataset/versions/1/OfficeHomeDataset_10072016'  # Update with actual path\n",
        "    source_domain = 'Clipart'\n",
        "    target_domain = 'Real World'\n",
        "    batch_size = 32\n",
        "    num_epochs = 50\n",
        "    lr = 0.001\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    # Data loaders\n",
        "    source_loader, target_loader = get_dataloaders(source_domain, target_domain, data_dir, batch_size)\n",
        "\n",
        "    # Model, optimizer\n",
        "    model = DANN(num_classes=65).to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    # Train\n",
        "    print(f'Training DANN: {source_domain} -> {target_domain}')\n",
        "    train_dann(model, source_loader, target_loader, optimizer, num_epochs, device)\n",
        "\n",
        "    # Evaluate\n",
        "    print('\\nEvaluating on source domain...')\n",
        "    source_acc = evaluate(model, source_loader, device)\n",
        "    print(f'Source ({source_domain}) Accuracy: {source_acc:.2f}%')\n",
        "\n",
        "    print('Evaluating on target domain...')\n",
        "    target_acc = evaluate(model, target_loader, device)\n",
        "    print(f'Target ({target_domain}) Accuracy: {target_acc:.2f}%')\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vu90S6dIJbsH",
        "outputId": "1ed2d548-e74f-4b85-d60e-df6ef17449be"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-11ad3fa6.pth\n",
            "100%|██████████| 97.8M/97.8M [00:00<00:00, 188MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training DANN: Clipart -> Real World\n",
            "Epoch [1/50]\n",
            "Class Loss: 2.9525, Domain Loss: 0.6589, Source Accuracy: 28.22%\n",
            "Epoch [2/50]\n",
            "Class Loss: 1.7517, Domain Loss: 0.6577, Source Accuracy: 54.50%\n",
            "Epoch [3/50]\n",
            "Class Loss: 1.1531, Domain Loss: 0.6158, Source Accuracy: 67.93%\n",
            "Epoch [4/50]\n",
            "Class Loss: 0.8442, Domain Loss: 0.6181, Source Accuracy: 76.43%\n",
            "Epoch [5/50]\n",
            "Class Loss: 0.6722, Domain Loss: 0.6164, Source Accuracy: 80.48%\n",
            "Epoch [6/50]\n",
            "Class Loss: 0.5402, Domain Loss: 0.6274, Source Accuracy: 84.22%\n",
            "Epoch [7/50]\n",
            "Class Loss: 0.4616, Domain Loss: 0.6537, Source Accuracy: 86.48%\n",
            "Epoch [8/50]\n",
            "Class Loss: 0.4893, Domain Loss: 0.6753, Source Accuracy: 85.54%\n",
            "Epoch [9/50]\n",
            "Class Loss: 0.3679, Domain Loss: 0.6874, Source Accuracy: 89.12%\n",
            "Epoch [10/50]\n",
            "Class Loss: 0.3408, Domain Loss: 0.6679, Source Accuracy: 90.03%\n",
            "Epoch [11/50]\n",
            "Class Loss: 0.3823, Domain Loss: 0.6798, Source Accuracy: 89.58%\n",
            "Epoch [12/50]\n",
            "Class Loss: 0.2962, Domain Loss: 0.6841, Source Accuracy: 92.12%\n",
            "Epoch [13/50]\n",
            "Class Loss: 0.2825, Domain Loss: 0.6760, Source Accuracy: 91.41%\n",
            "Epoch [14/50]\n",
            "Class Loss: 0.2945, Domain Loss: 0.6787, Source Accuracy: 91.71%\n",
            "Epoch [15/50]\n",
            "Class Loss: 0.2889, Domain Loss: 0.6759, Source Accuracy: 91.89%\n",
            "Epoch [16/50]\n",
            "Class Loss: 0.2613, Domain Loss: 0.6797, Source Accuracy: 92.49%\n",
            "Epoch [17/50]\n",
            "Class Loss: 0.2374, Domain Loss: 0.6750, Source Accuracy: 93.17%\n",
            "Epoch [18/50]\n",
            "Class Loss: 0.1994, Domain Loss: 0.6828, Source Accuracy: 94.09%\n",
            "Epoch [19/50]\n",
            "Class Loss: 0.3568, Domain Loss: 0.6838, Source Accuracy: 90.10%\n",
            "Epoch [20/50]\n",
            "Class Loss: 0.2095, Domain Loss: 0.6645, Source Accuracy: 94.27%\n",
            "Epoch [21/50]\n",
            "Class Loss: 0.2230, Domain Loss: 0.6768, Source Accuracy: 93.81%\n",
            "Epoch [22/50]\n",
            "Class Loss: 0.2372, Domain Loss: 0.6704, Source Accuracy: 93.10%\n",
            "Epoch [23/50]\n",
            "Class Loss: 0.2009, Domain Loss: 0.6809, Source Accuracy: 94.46%\n",
            "Epoch [24/50]\n",
            "Class Loss: 0.2524, Domain Loss: 0.6738, Source Accuracy: 92.76%\n",
            "Epoch [25/50]\n",
            "Class Loss: 0.2236, Domain Loss: 0.6752, Source Accuracy: 93.70%\n",
            "Epoch [26/50]\n",
            "Class Loss: 0.1976, Domain Loss: 0.6856, Source Accuracy: 94.59%\n",
            "Epoch [27/50]\n",
            "Class Loss: 0.2695, Domain Loss: 0.6933, Source Accuracy: 92.07%\n",
            "Epoch [28/50]\n",
            "Class Loss: 0.2146, Domain Loss: 0.6690, Source Accuracy: 94.14%\n",
            "Epoch [29/50]\n",
            "Class Loss: 0.2133, Domain Loss: 0.6720, Source Accuracy: 94.07%\n",
            "Epoch [30/50]\n",
            "Class Loss: 0.2021, Domain Loss: 0.6783, Source Accuracy: 94.16%\n",
            "Epoch [31/50]\n",
            "Class Loss: 0.1639, Domain Loss: 0.6668, Source Accuracy: 94.94%\n",
            "Epoch [32/50]\n",
            "Class Loss: 0.1741, Domain Loss: 0.6807, Source Accuracy: 95.01%\n",
            "Epoch [33/50]\n",
            "Class Loss: 0.2362, Domain Loss: 0.6712, Source Accuracy: 92.90%\n",
            "Epoch [34/50]\n",
            "Class Loss: 0.1596, Domain Loss: 0.6899, Source Accuracy: 95.01%\n",
            "Epoch [35/50]\n",
            "Class Loss: 0.1842, Domain Loss: 0.6787, Source Accuracy: 95.10%\n",
            "Epoch [36/50]\n",
            "Class Loss: 0.1875, Domain Loss: 0.6759, Source Accuracy: 94.25%\n",
            "Epoch [37/50]\n",
            "Class Loss: 0.1532, Domain Loss: 0.6730, Source Accuracy: 95.49%\n",
            "Epoch [38/50]\n",
            "Class Loss: 0.1913, Domain Loss: 0.6713, Source Accuracy: 94.48%\n",
            "Epoch [39/50]\n",
            "Class Loss: 0.1356, Domain Loss: 0.6905, Source Accuracy: 95.62%\n",
            "Epoch [40/50]\n",
            "Class Loss: 0.2384, Domain Loss: 0.6982, Source Accuracy: 93.15%\n",
            "Epoch [41/50]\n",
            "Class Loss: 0.1649, Domain Loss: 0.6741, Source Accuracy: 94.82%\n",
            "Epoch [42/50]\n",
            "Class Loss: 0.1844, Domain Loss: 0.6867, Source Accuracy: 94.91%\n",
            "Epoch [43/50]\n",
            "Class Loss: 0.1632, Domain Loss: 0.6861, Source Accuracy: 94.98%\n",
            "Epoch [44/50]\n",
            "Class Loss: 0.1449, Domain Loss: 0.6866, Source Accuracy: 95.69%\n",
            "Epoch [45/50]\n",
            "Class Loss: 0.1988, Domain Loss: 0.6939, Source Accuracy: 95.03%\n",
            "Epoch [46/50]\n",
            "Class Loss: 0.1267, Domain Loss: 0.6649, Source Accuracy: 96.01%\n",
            "Epoch [47/50]\n",
            "Class Loss: 0.1433, Domain Loss: 0.6796, Source Accuracy: 95.58%\n",
            "Epoch [48/50]\n",
            "Class Loss: 0.1349, Domain Loss: 0.6770, Source Accuracy: 95.92%\n",
            "Epoch [49/50]\n",
            "Class Loss: 0.1149, Domain Loss: 0.6768, Source Accuracy: 96.17%\n",
            "Epoch [50/50]\n",
            "Class Loss: 0.1519, Domain Loss: 0.6853, Source Accuracy: 95.53%\n",
            "\n",
            "Evaluating on source domain...\n",
            "Source (Clipart) Accuracy: 96.52%\n",
            "Evaluating on target domain...\n",
            "Target (Real World) Accuracy: 39.59%\n"
          ]
        }
      ]
    }
  ]
}